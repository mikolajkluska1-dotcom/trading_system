import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sklearn.preprocessing import MinMaxScaler
import time
import os

# --- KONFIGURACJA POD 64GB RAM ---
MODEL_SAVE_PATH = "R:/REDLINE_SYSTEM/ai_models/btc_lstm_v2.pth" 
SYMBOL = "BTC/USDT"
SEQ_LENGTH = 60    # Analizujemy 60 minut wstecz
HIDDEN_SIZE = 100  # ZWIƒòKSZAMY M√ìZG (z 50 na 100 neuron√≥w, bo mamy du≈ºo danych)
EPOCHS = 10        # 10 epok wystarczy przy takiej ilo≈õci danych
BATCH_SIZE = 4096  # OGROMNY BATCH (dziƒôki 64GB RAM trening bƒôdzie szybki)

# Dostƒôp do bazy (Docker port 5435)
DB_URL = "postgresql://redline_user:redline_pass@localhost:5435/redline_db"

print(f"üöÄ START: Trening M√≥zgu V2 (Massive) dla {SYMBOL}")
print(f"üíæ Cel zapisu: {MODEL_SAVE_PATH}")
print("-" * 50)

# 1. PO≈ÅƒÑCZENIE Z BAZƒÑ (Wczytywanie do RAM)
print("‚è≥ Pobieranie 900k+ wierszy z SQL do RAMu... (Masz 64GB, wiƒôc to piku≈õ)")
start_load = time.time()

engine = create_engine(DB_URL)
# Pobieramy czas i cenƒô zamkniƒôcia, posortowane
query = f"""
    SELECT close 
    FROM market_candles 
    WHERE symbol = '{SYMBOL}' 
    ORDER BY time ASC
"""
df = pd.read_sql(query, engine)

load_time = time.time() - start_load
print(f"‚úÖ Pobrano {len(df)} wierszy w {load_time:.2f}s")

if len(df) < 100000:
    print("‚ùå ZA MA≈ÅO DANYCH! Co≈õ posz≈Ço nie tak z pobieraniem.")
    exit()

# 2. PRZYGOTOWANIE DANYCH
print("‚öôÔ∏è Przetwarzanie i skalowanie...")
data = df['close'].values.reshape(-1, 1)

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Funkcja tworzƒÖca sekwencje (szybka wersja wektorowa)
# Zamieniamy listƒô cen na pary: [60 cen wstecz] -> [cena teraz]
def create_sequences(data, seq_length):
    xs = []
    ys = []
    # To mo≈ºe chwilƒô potrwaƒá, ale przy 64GB RAM nie wywali b≈Çƒôdu
    for i in range(len(data) - seq_length):
        x = data[i:(i + seq_length)]
        y = data[i + seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

X, y = create_sequences(scaled_data, SEQ_LENGTH)

# Konwersja na Tensory PyTorch
X = torch.from_numpy(X).float()
y = torch.from_numpy(y).float()

# Podzia≈Ç: 90% trening, 10% test (bo mamy ogromnƒÖ bazƒô)
split_idx = int(len(X) * 0.9)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

# Loader na GPU/CPU
train_loader = torch.utils.data.DataLoader(
    torch.utils.data.TensorDataset(X_train, y_train), 
    batch_size=BATCH_SIZE, 
    shuffle=False
)

print(f"üß† Gotowe do nauki. Pr√≥bek treningowych: {len(X_train)}")

# 3. MODEL SIECI NEURONOWEJ (V2 - Wiƒôkszy)
class CryptoLSTM(nn.Module):
    def __init__(self, input_size=1, hidden_size=100, output_size=1):
        super(CryptoLSTM, self).__init__()
        # 2 warstwy LSTM dla g≈Çƒôbszego zrozumienia
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üñ•Ô∏è UrzƒÖdzenie obliczeniowe: {device}")

model = CryptoLSTM(hidden_size=HIDDEN_SIZE).to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 4. TRENING
print("\nü•ä ROZPOCZYNAM WALKƒò (TRENING)...")
start_train = time.time()

for epoch in range(EPOCHS):
    model.train()
    epoch_loss = 0
    steps = 0
    
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
        steps += 1
    
    avg_loss = epoch_loss / steps
    print(f"   Epoch [{epoch+1}/{EPOCHS}] | Loss: {avg_loss:.6f} | Czas: {time.time()-start_train:.0f}s")

# 5. ZAPIS
if not os.path.exists("R:/REDLINE_SYSTEM/ai_models"):
    os.makedirs("R:/REDLINE_SYSTEM/ai_models")

torch.save(model.state_dict(), MODEL_SAVE_PATH)
print("=" * 50)
print(f"üéâ SUKCES! M√≥zg V2 (na 900k ≈õwiecach) zapisany w: {MODEL_SAVE_PATH}")